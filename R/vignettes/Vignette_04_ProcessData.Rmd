---
title: "Vignette 04: Process Data"
author: "Grace Smith-Vidaurre"
date: "2023-12-27"
output: html_document
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(echo = TRUE, eval = TRUE)

```

<h2>Vignette Overview and Learning Objectives</h2>

In this fourth vignette, you will pre-process the simulated datasets of animal movements detected by different sensors. Throughout the process of data pre-processing, you will continue to use coding skills that you learned in the previous vignettes, and you will learn additional skills that include:

1. Sourcing custom functions
2. Using custom functions
2. Reading files from your computer into R

<h2>Load packages and your working directory path</h2>

```{r message = FALSE, warning = FALSE}

rm(list = ls()) # Clean global environment

library(tidyverse) # Load the set of tidyverse packages

path <- "/home/gsvidaurre/Desktop/ABISSMAL_vignettes" # Initialize an object with the path that is your working directory

```


<h3>Create a final data frame for the RFID data</h3>

In the chunks of code above that inserted `glimpse()` between piping operations, you did not save the modifications that you made to `sim_dats` in an object (the output was printed to the console only). You can create an object with the updated data frame now. You'll also add another column with 2 unique PIT tag identifiers (1 for each simulated individual), and a column with the sensor type:
```{r}

# Make a vector for the experimental replicate
exp_rep <- rep(x = "Pair_01", times = length(rfid_ts))

# Make the data frame with the experimental replicate metadata and the timestamps
sim_dats_rfid <- data.frame(replicate = exp_rep, timestamps = rfid_ts)

# Overwrite the data frame with the modified version that has columns for the year, month, and day
sim_dats_rfid <- sim_dats_rfid %>%
  dplyr::mutate(
    year = 2023
  ) %>%
  dplyr::mutate(
    month = 08,
    day = 01
  ) %>%
  # Allocate the first half of the detections to the first individual using nrow(.)/2, and the second half of the detctions to the second individual using nrow(.)/2 again. Both of the rep() expressions are combined into a single vector using the c() function
  dplyr::mutate(
    PIT_tag = c(rep("1357aabbcc", nrow(.)/2), rep("2468zzyyxx", nrow(.)/2))
  ) %>% 
  dplyr::mutate(
    sensor_id = "RFID"
  )

glimpse(sim_dats_rfid)

```

You can simulate data collection over more than one day as well. To create more observations (rows) for two additional days, you can append rows from a modified copy of `sim_dats_rfid` to itself. In the code below, you're piping `sim_dats_rfid` into `bind_rows()`, which indicates that this is the object to which you want to append rows. Then the code inside of `bind_rows()` indicates the data frame (rows) that will be appended to `sim_dats_rfid`. In this case, the code inside of `bind_rows()` pipes `sim_dats_rfid` into `dplyr::mutate()`, which you're using to modify the `day` column to reflect a subsequent day of data collection.
```{r}

sim_dats_rfid <- sim_dats_rfid %>% 
  bind_rows(
    sim_dats_rfid %>% 
      dplyr::mutate(
        day = 02
      )
  )

glimpse(sim_dats_rfid) # Double the number of rows, looks good

```

<h3>Check data frame columns with base R</h3>

You checked that simulated data frame has data collected over two days looking at the structure of the new object. You can also check the unique values present in the column `day`. Below is a way of checking the unique values contained in a column of a data frame, using two different examples of base R notation for accessing columns:
```{r}

# The name of a data frame object, followed by a $ sign and then the name of a column allows you to pull out one column at a time from a data frame. A data frame column is a vector, so when you run this code you will see a vector of values print to the console
sim_dats_rfid$day

# You can also access a column in a data frame by using double square brackets after the name of the data frame, and placing the column name in quotes inside of the inner brackets
sim_dats_rfid[["day"]]

# You can use the function unique() to see the unique values of any vector, including a column of a data frame
unique(sim_dats_rfid$day) # Two days, looks good

unique(sim_dats_rfid[["day"]]) # Two days, looks good

```

<h3>Check data frame columns with the tidyverse</h3>

You can also check the unique values in a column using functions from the tidyverse. In the expression below, you're piping `sim_dats_rfid` into the function `pull()`, which lets you pull the column `day` out of the data frame as a vector, and then that vector is piped into the function `unique()` to check the unique values contained in the vector. The function `unique()` does not need an argument inside of the parentheses here because you're already piping the output that it needs directly into the function.
```{r}

# Two days, looks good
sim_dats_rfid %>% 
  pull(day) %>% 
  unique()

```

<h3>Create a final data frame for the beam breaker data</h3>

Next, repeat this process of creating a data frame with metadata for the infrared beam breaker dataset. Since the beam breakers do not collect unique individual identity information, you will add columns for the year, month, day, and sensor type. You will also simulate data collection for the beam breakers over the same two days as the RFID system.
```{r}

# Overwrite the vector exp_rep with a new vector the same length as irbb_ts
exp_rep <- rep(x = "Pair_01", times = length(irbb_ts))

sim_dats_irbb <- data.frame(replicate = exp_rep, timestamps = irbb_ts)

sim_dats_irbb <- sim_dats_irbb %>%
  dplyr::mutate(
    year = 2023,
    month = 08,
    day = 01,
    sensor_id = "Beam breakers"
  )

glimpse(sim_dats_irbb)

sim_dats_irbb <- sim_dats_irbb %>% 
  bind_rows(
    sim_dats_irbb %>% 
      dplyr::mutate(
        day = 02
      )
  )

glimpse(sim_dats_irbb) # Double the number of rows, looks good

# Two days, looks good
sim_dats_irbb %>% 
  pull(day) %>% 
  unique()

```

<h2>Save each data frame per day as a physical file</h2>

Now that you made data frames of the timestamps and metadata per sensor, you can write out or save these data frames as physical files in your working directory. You have many different file type options, but I recommend using .csv format for data frames since this file type is compatible with R as well as Microsoft Word and other programs like LibreOffice.

In the code below, you'll write out a spreadsheet per sensor for each day of data collection. In order to write out a spreadsheet per day, you need to filter the rows of the full data frame for each sensor by date. To do this filtering, you'll use a conditional statement inside of the function `dplyr::filter()`:
```{r}

# Pipe the data frame into the filter() function
sim_dats_rfid %>% 
  # Filter the data frame by pulling out all rows in which the day column was equal to 1
  dplyr::filter(day == 1) %>%
  glimpse()

# One day, looks good
sim_dats_rfid %>% 
  dplyr::filter(day == 1) %>%
  pull(day) %>% 
  unique()

```

You can now use this `dplyr::filter()` function as you write out a spreadsheet per day. In the code below, you will create a custom file name for the 1st day of RFID data, then you'll filter the RFID data frame by the first day and write it out as a .csv file:
```{r eval = FALSE}

?write.csv

# For the RFID data, create a vector of the working directory and the file name that you will use for the argument file in write.csv()
# The function file.path() will combine both pieces of information into a single file path
rfid_file <- file.path(path, "RFID_simulated_Pair-01_2023_08_01.csv")
rfid_file

sim_dats_rfid %>% 
  dplyr::filter(day == 1) %>% 
  # Write out the data frame as a .csv spreadsheet. Do not include row names
  # Remember that the "." means the function will use the object that is piped in, which here is the data frame filtered by day 1
  write.csv(x = ., file = rfid_file, row.names = FALSE)

```

As specified in the function documentation for `write.csv()`, the function will include column names in the resulting spreadsheet by default. The function will also not append new information to the .csv if it already exists. If you already created this file then it will be overwritten when you run the function again.

Repeat this process for the second day of RFID data:
```{r}

rfid_file <- file.path(path, "RFID_simulated_Pair-01_2023_08_02.csv")
rfid_file

sim_dats_rfid %>% 
  dplyr::filter(day == 2) %>% 
  write.csv(x = ., file = rfid_file, row.names = FALSE)

```

You can also write out a spreadsheet per day for the infrared beam breaker dataset.
```{r eval = FALSE}

irbb_file <- file.path(path, "IRBB_simulated_Pair-01_2023_08_01.csv")
irbb_file

sim_dats_irbb %>% 
  dplyr::filter(day == 1) %>% 
  # By default, write.csv() will write out the object that is piped in, so you don't need to specify "x = ."
  write.csv(irbb_file, row.names = FALSE)

irbb_file <- file.path(path, "IRBB_simulated_Pair-01_2023_08_02.csv")
irbb_file

sim_dats_irbb %>% 
  dplyr::filter(day == 2) %>% 
  # By default, write.csv() will write out the object that is piped in, so you don't need to specify "x = ."
  write.csv(irbb_file, row.names = FALSE)

```

Check that these 2 files now exist in your working directory.
```{r eval = FALSE}

list.files(path)

```


<h2>Load ABISSMAL functions</h2>

In this vignette, you will use the the R functions available through the ABISSMAL GitHub repository. These functions are stored in physical files (extension .R) inside the local version of the ABISSMAL repository on your computer. You need to load these files into R so that the functions you want to use are available in your global environment.
```{r}

# Load the function that combines raw data
source("/home/gsvidaurre/Desktop/GitHub_repos/ABISSMAL/R/combine_raw_data.R")

# Load the function that detects perching events in the raw data
source("/home/gsvidaurre/Desktop/GitHub_repos/ABISSMAL/R/detect_perching_events.R")

# Load the function that pre-processes raw data
source("/home/gsvidaurre/Desktop/GitHub_repos/ABISSMAL/R/preprocess_detections.R")

# Load a script with utility functions that each function above requires
source("/home/gsvidaurre/Desktop/GitHub_repos/ABISSMAL/R/utilities.R")

```

After running the lines of code above, you should see that a whole set of functions have been loaded into your global environment (check the `Environment` pane). Many of these functions start with `check_`, and those are utility functions. If you scroll down, you'll see that the three main functions above (`combine_raw_data`, `detect_perching_events`, `preprocess_detections`) are all loaded in your global environment. In the column to the right of the function names you can also see a preview of each function's arguments. 

To get more information about each of these three main functions, you can click the white square icon to the very right of each function in the `Environment` pane, or run the code `View(function_name)`. This will open the script for the given function a new tab in your Source pane. In each script for each function, you'll see lines of documentation starting with the symbols "`# @". You'll see the function name and description first, and then a description of each argument (parameter) for the function. If you keep scrolling down, you'll see a section with details about how the given function works, and the information that it returns. After the lines of documentation, you'll see the code that makes up the function itself. 


<h2>Combine raw data</h2>
